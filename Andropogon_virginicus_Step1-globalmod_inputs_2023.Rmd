---
title: "Andropogon virginicus - Preparing Global Model Inputs"
author: "Kelsey Brock"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r}
starttime <- Sys.time()
```


# Name of Species being modelled


Change the species name!  And keep it in this format
```{r}
spname <- "Andropogon_virginicus"
```
# Set up
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,error=TRUE,message=FALSE)
```
```{r}
#get the needed packages
if(!require("pacman")){
	install.packages("pacman")
	library(pacman)}
p_load("dplyr",  "tidyr", "ggplot2", "terra",  "sf", "sp",  "CoordinateCleaner",  "spThin", "rgdal", "data.table")
```

Make a note about how to set up folders here.
```{r}
# setting paths
  path.root <- "~/codingwork/fire"  # typical class root dir
  path.in.general <- paste(path.root, "/input", sep = "")
  path.in.specific <- paste(path.root, "/input/", spname, sep = "")
  path.out <- paste(path.root, "/output/", spname, sep = "") 
```

```{r}
# handy projection string
prj.wgs84 <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"  # epsg:4326
```


####  Get the Occurrence Data
```{r}
pres <- read.csv(paste(path.in.general, "/occurrence_data/", spname, ".csv", sep = ""), header=T, sep=',', stringsAsFactors=F)
head(pres) # look at data
```

This chunk of code changes the species names to 1s to indicate presences.  If it doesn't change, you must replace spname to whatever you see in the Species column in the gsub function below
```{r}
pres$scientificName <- gsub(spname, 1, pres$scientificName)
head(pres, 2)
```
Make sure we only have 1s
```{r}
unique(pres$scientificName)
```
How many 1s (presences)  do we have?
```{r}
nrow(pres)
```

### Clean Coordinates

```{r}
flagged <- clean_coordinates(x = pres, species = "scientificName", lon = "decimalLongitude", lat = "decimalLatitude",
                             tests = c( "centroids","equal", "seas", "zeros"))
summary(flagged)
```
```{r}
table(flagged$.summary)
```
```{r}
pres <- subset(flagged, flagged$.summary == TRUE)
dim(pres)
```


#### GLOBAL Spatial thinning (takes a long time)

```{r}
break1 <-nrow(pres)* .20
break2 <-nrow(pres)* .40
break3 <-nrow(pres)* .60
break4 <-nrow(pres)* .80

pres1 <- pres[1:break1,]
pres2 <- pres[break1:break2, ]
pres3 <- pres[break2:break3, ]
pres4 <- pres[break3:break4, ]
pres5 <- pres[break4:nrow(pres), ]
```

```{r}
kms_to_thin_by <- 30
```

```{r}
output1 <- spThin::thin(pres1, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
```
```{r}
output2 <- spThin::thin(pres2, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
```
```{r}
output3 <- spThin::thin(pres3, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
```
```{r}
output4 <- spThin::thin(pres4, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
```
```{r}
output5 <- spThin::thin(pres5, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
# find the iteration that returns the max number of occurrences

```
Since spThin did 100 iterations, there are 100 different variations of
how it thinned the occurrence localities. As there is a stochastic
element in the algorithm, some iterations may include more localities
than the others, and we need to make sure we maximize the number of
localities we proceed with.

```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output1, nrow) == max(sapply(output1, nrow)))
# if there's more than one max, pick the first one
maxThin <- output1[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres1 <- pres1[as.numeric(rownames(maxThin)),]  

```
```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output2, nrow) == max(sapply(output2, nrow)))
# if there's more than one max, pick the first one
maxThin <- output2[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres2 <- pres2[as.numeric(rownames(maxThin)),]  
```
```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output3, nrow) == max(sapply(output3, nrow)))
# if there's more than one max, pick the first one
maxThin <- output3[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres3 <- pres3[as.numeric(rownames(maxThin)),]  

```
```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output4, nrow) == max(sapply(output4, nrow)))
# if there's more than one max, pick the first one
maxThin <- output4[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres4 <- pres4[as.numeric(rownames(maxThin)),]  

```
```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output5, nrow) == max(sapply(output5, nrow)))
# if there's more than one max, pick the first one
maxThin <- output5[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres5 <- pres5[as.numeric(rownames(maxThin)),]  

```

```{r}
pres <- as.data.frame(rbind(pres1, pres2, pres3, pres4,pres5))
pres
```

```{r}
output <- spThin::thin(pres, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 1, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE)
```

```{r}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))
# if there's more than one max, pick the first one
maxThin <- output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
pres <- pres[as.numeric(rownames(maxThin)),]  
pres
```


save the raw points that were used
```{r}
setwd(path.in.specific)
write.csv(pres, paste0(spname, "_occurrences_used.csv"), row.names = FALSE)
```

```{r}
setwd(path.in.specific)
pres <- read.csv(paste(spname, "_occurrences_used.csv", sep = ""), header=T, sep=',', stringsAsFactors=F)
```

#### Converting to a spatial object with a geometry field
```{r}
pres <- st_as_sf(pres, coords = c("decimalLongitude", "decimalLatitude"), crs = prj.wgs84, remove = FALSE)
class(pres)
head(pres, 4)
```

#### Subset into local versus Global dataset

```{r}
setwd(path.in.general)
#This polygon is only for the main hawaiian islands
islandpolys <- st_read("Coastline.shp")
```


```{r}
local.pres <- st_join(pres, islandpolys, join = st_intersects, left = FALSE ) %>% dplyr::select(scientificName, decimalLongitude, decimalLatitude, isle,	geometry)
unique(local.pres$isle)
dim(local.pres)
head(local.pres)
```
#### Check:

```{r}
plot(st_geometry(islandpolys), border = "darkgrey", axes = F)
plot(st_geometry(local.pres),  add= T, col = "red", pch = 16)
```
```{r}
worldmap <- borders("world", colour = "white", fill = "gray75")
map_world <- ggplot() +
                worldmap +
                geom_point(local.pres, mapping = aes(x = decimalLongitude, y = decimalLatitude), col = "red")
map_world
```
```{r}
global.pres <- st_join(pres, islandpolys, join = st_intersects,  left = TRUE ) %>%
  subset(is.na(isle)) %>%
  dplyr::select(scientificName, decimalLongitude, decimalLatitude, isle,	geometry)
unique(global.pres$isle)
dim(global.pres)
head(global.pres)
```
```{r}
plot(st_geometry(islandpolys), border = "darkgrey", axes = F)
plot(st_geometry(global.pres),  add= T, col = "red", pch = 16)
```
```{r}
worldmap <- borders("world", colour = "white", fill = "gray75")
map_world <- ggplot() +
                worldmap +
                geom_point(global.pres, mapping = aes(x = decimalLongitude, y = decimalLatitude), col = "red")
map_world
```



<!-- # GETTING HAWAII OCC POINTS THINNED & PREPPED -->
<!-- just running this again because I'm too lazy to make better -->

<!-- ####  Get the Occurrence Data -->
<!-- ```{r} -->
<!-- pres <- read.csv(paste(path.in.general, "/occurrence_data/", spname, ".csv", sep = ""), header=T, sep=',', stringsAsFactors=F) -->
<!-- head(pres) # look at data -->
<!-- ``` -->
<!-- ```{r} -->
<!-- pres$scientificName <- gsub(spname, 1, pres$scientificName) -->
<!-- head(pres, 2) -->
<!-- ``` -->

<!-- How many 1s (presences)  do we have? -->
<!-- ```{r} -->
<!-- nrow(pres) -->
<!-- ``` -->

<!-- ### Clean Coordinates -->

<!-- ```{r} -->
<!-- flagged <- clean_coordinates(x = pres, species = "scientificName", lon = "decimalLongitude", lat = "decimalLatitude",  -->
<!--                              tests = c( "centroids","equal", "seas", "zeros")) -->
<!-- summary(flagged) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- table(flagged$.summary) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- pres <- subset(flagged, flagged$.summary == TRUE) -->
<!-- dim(pres) -->
<!-- ``` -->
<!-- #### Spatial thinning (takes a long time) -->


<!-- ```{r} -->
<!-- break1 <-nrow(pres)* .20 -->
<!-- break2 <-nrow(pres)* .40 -->
<!-- break3 <-nrow(pres)* .60 -->
<!-- break4 <-nrow(pres)* .80 -->

<!-- pres1 <- pres[1:break1,] -->
<!-- pres2 <- pres[break1:break2, ] -->
<!-- pres3 <- pres[break2:break3, ] -->
<!-- pres4 <- pres[break3:break4, ] -->
<!-- pres5 <- pres[break4:nrow(pres), ] -->
<!-- ``` -->

<!-- ```{r} -->
<!-- kms_to_thin_by <- 30 -->
<!-- ``` -->

<!-- ```{r} -->
<!-- output1 <- spThin::thin(pres1, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- output2 <- spThin::thin(pres2, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- output3 <- spThin::thin(pres3, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- output4 <- spThin::thin(pres4, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- output5 <- spThin::thin(pres5, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 3, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- # find the iteration that returns the max number of occurrences -->

<!-- ``` -->
<!-- Since spThin did 100 iterations, there are 100 different variations of -->
<!-- how it thinned the occurrence localities. As there is a stochastic -->
<!-- element in the algorithm, some iterations may include more localities -->
<!-- than the others, and we need to make sure we maximize the number of -->
<!-- localities we proceed with. -->

<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output1, nrow) == max(sapply(output1, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output1[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres1 <- pres1[as.numeric(rownames(maxThin)),]   -->

<!-- ``` -->
<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output2, nrow) == max(sapply(output2, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output2[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres2 <- pres2[as.numeric(rownames(maxThin)),]   -->
<!-- ``` -->
<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output3, nrow) == max(sapply(output3, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output3[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres3 <- pres3[as.numeric(rownames(maxThin)),]   -->

<!-- ``` -->
<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output4, nrow) == max(sapply(output4, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output4[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres4 <- pres4[as.numeric(rownames(maxThin)),]   -->

<!-- ``` -->
<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output5, nrow) == max(sapply(output5, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output5[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres5 <- pres5[as.numeric(rownames(maxThin)),]   -->

<!-- ``` -->

<!-- ```{r} -->
<!-- pres <- as.data.frame(rbind(pres1, pres2, pres3, pres4,pres5)) -->
<!-- pres -->
<!-- ``` -->

<!-- ```{r} -->
<!-- output <- spThin::thin(pres, lat.col = 'decimalLatitude', long.col = 'decimalLongitude', spec.col = "scientificName", thin.par = (kms_to_thin_by ), reps = 1, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = TRUE) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # find the iteration that returns the max number of occurrences -->
<!-- maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow))) -->
<!-- # if there's more than one max, pick the first one -->
<!-- maxThin <- output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]   -->
<!-- # subset occs to match only thinned occs -->
<!-- pres <- pres[as.numeric(rownames(maxThin)),]   -->
<!-- pres -->
<!-- ``` -->



<!-- #### Converting to a spatial object with a geometry field -->
<!-- ```{r} -->
<!-- pres <- st_as_sf(pres, coords = c("decimalLongitude", "decimalLatitude"), crs = prj.wgs84, remove = FALSE) -->
<!-- class(pres) -->
<!-- head(pres, 4) -->
<!-- ``` -->

<!-- #### Subset into local versus local dataset -->

<!-- ```{r} -->
<!-- setwd(path.in.general) -->
<!-- #This polygon is only for the main hawaiian islands -->
<!-- islandpolys <- st_read("Coastline.shp") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- local.pres <- st_join(pres, islandpolys, join = st_intersects, left = FALSE ) %>% dplyr::select(scientificName, decimalLongitude, decimalLatitude, isle,	geometry) -->
<!-- unique(local.pres$isle) -->
<!-- dim(local.pres) -->
<!-- head(local.pres) -->
<!-- ``` -->
<!-- #### Check: -->

<!-- ```{r} -->
<!-- plot(st_geometry(islandpolys), border = "darkgrey", axes = F) -->
<!-- plot(st_geometry(local.pres),  add= T, col = "red", pch = 16) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- worldmap <- borders("world", colour = "white", fill = "gray75") -->
<!-- map_world <- ggplot() + -->
<!--                 worldmap + -->
<!--                 geom_point(local.pres, mapping = aes(x = decimalLongitude, y = decimalLatitude), col = "red") -->
<!-- map_world -->
<!-- ``` -->

<!-- save the raw points that were used -->
<!-- ```{r} -->
<!-- setwd(path.in.specific) -->
<!-- write.csv(local.pres, paste0(spname, "_occurrences_used_local.csv"), row.names = FALSE) -->
<!-- ``` -->



# GLOBAL MODEL

#### making a bounding box (with  buffered points)

```{r}
buffer = 450

#global.bufbbox <- extent(min(global.pres$decimalLongitude) - (0.00833 * buffer), max(global.pres$decimalLongitude) + (0.00833 * buffer),
#               min(global.pres$decimalLatitude) - (0.00833 * buffer), max(global.pres$decimalLatitude) + (0.00833 * buffer))

#making a bbox of the entire world, excluding the arctic and antarctica

xmin = -179.9999
xmax =  179.9999
ymin = -61
ymax =  61

global.bufbbox <- terra::ext(xmin, xmax, ymin, ymax)

global.bufbbox
```
```{r}
global.bufbboxSF <- st_as_sfc(st_bbox(global.bufbbox, crs = prj.wgs84))
global.bufbboxSF
```
```{r}
plot(st_geometry(global.bufbboxSF), axes = T)
plot(st_geometry(global.pres), add= T, col = "darkgreen")
```
#### Making a SF polygon of the buffered points

```{r}
global.bufptSF <- sf::st_buffer(global.pres, dist = (0.00833 * 50000 * buffer))

#union-ing the points into a single polygon
global.bufptSF <- sf::st_union(global.bufptSF)
plot(st_geometry(global.bufptSF), axes = T)
```

#### Saving
(This will be domain where the statistical model will be projected later on)

```{r}
setwd(path.in.specific)
save("global.bufptSF", file = paste0(spname, "_global.bufptSF.RData"))
save("global.bufbboxSF", file = paste0(spname, "_global.bufbbox.RData"))
```

```{r}
setwd(path.in.specific)
global.bufptSF <- get(load(file = paste0(spname, "_global.bufptSF.RData")))
global.bufbboxSF <- get(load(file = paste0(spname, "_global.bufbbox.RData")))
```



## Building a Global "Fishnet"

This creates a dataframe of gridcells to associate with presence points, so that each presence point can be assigned a FNETID

#### converting buffered pt polygon to raster using a template raster file
```{r}
setwd(path.in.general)
template1 <- terra::rast("gpw_v4_land_water_area_rev11_landareakm_30_sec.tif")
template1
```

Let’s make sure the projections are the same:
```{r}
st_crs(template1)$proj4string == st_crs(global.bufbboxSF)$proj4string
```
```{r}
st_crs(global.bufbboxSF)$proj4string == st_crs(global.bufptSF)$proj4string
```
```{r}
global.bufbboxSP <- as_Spatial(global.bufbboxSF) # converts to spatial polygon class\
global.bufbboxSP
```
If this step throws an error, just try running it one more time.
```{r}
step1 <- terra::vect(global.bufbboxSF)

step2 <-terra::rasterize(step1, template1)

global.bufboxR <- terra::crop(step2, global.bufbboxSF)

plot(global.bufboxR, legend = T)
```

```{r}
step1 <- terra::vect(global.bufptSF)

step2 <-terra::rasterize(step1, template1)

global.bufptR <- terra::crop(step2, global.bufptSF)

plot(global.bufptR)
```


### You'll only have to do this once; highlight and shift +ctrl +c to uncomment
<!-- ``` -->

<!-- ```{r} -->
<!-- global.bufboxR <- terra::crop(terra::rasterize(global.bufbboxSP, template1), global.bufbboxSP) # cropping to bbox -->
<!-- global.bufboxR -->
<!-- ``` -->
<!-- ```{r} -->
<!-- plot(global.bufboxR, legend = T) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- global.bufptSP <- as_Spatial(global.bufptSF) # converts to spatial polygon class -->
<!-- global.bufptR <- crop(rasterize(global.bufptSP, template1), global.bufptSP) # cropping to bbox -->
<!-- global.bufptR -->
<!-- ``` -->
<!-- ```{r} -->
<!-- plot(global.bufptR, legend = T) -->
<!-- ``` -->

<!-- #### Save -->
<!-- ```{r} -->
<!-- setwd(path.in.general) -->
<!-- writeRaster(global.bufboxR, filename = "global.bboxR.tif", overwrite = TRUE) -->
<!-- ``` -->
#### Open

```{r}
setwd(path.in.general)
global.bufboxR <- terra::rast("global.bboxR.tif")
global.bufboxR
```

#### Save
```{r}
setwd(path.in.specific)
writeRaster(global.bufptR, filename = paste0(spname, "_global.bufptR.tif"), overwrite = TRUE)
```

#### Open

```{r}
setwd(path.in.specific)
global.bufptR <- terra::rast(paste0(spname, "_global.bufptR.tif"))
global.bufptR
```

### Making a df of that buffered pt raster file


```{r}
df3 <- terra::as.data.frame(global.bufptR, row.names=NULL, cells = TRUE, xy = TRUE)
```


```{r}
# some dataframe clean-up
names(df3)[1:3] <- c("FNETID","decimalLongitude", "decimalLatitude" ) # assign names
df3 <- df3[c("FNETID", "decimalLongitude", "decimalLatitude")] # reorder
class(df3)
head(df3)
```
```{r}
length(unique(df3$FNETID)) == nrow(df3)
```

```{r}
setwd(path.in.general)
#saveRDS("f3", file = "f3.rds")
fwrite(df3, file = "df3.csv", sep = ",")
```
```{r}
setwd(path.in.general)
df3 <- fread("df3.csv")
head(df3)
```

### Extract fishnet location points for each presence point
#### convert species presences x,y to spatial coordinate

```{r}
global.presDF <- st_drop_geometry(global.pres) # build dataframe -  redundant, but whatever
class(global.presDF)
```

```{r}
tru.xy <- global.presDF[c("decimalLongitude", "decimalLatitude")]  # get x,y of species presences
p1 <- sp::coordinates(tru.xy)
head(p1)
```
### Get FNETIDs that have spp presences

```{r}
#pres.fnetid <- cellFromXY(global.bufboxR, p1)
pres.fnetid <- cellFromXY(global.bufptR, p1) # FNETID of presence from pt-buffered poly
length(pres.fnetid)
head(pres.fnetid, 25) # FNETID numbers associated with species x,y
```
#### Check:

Make sure the species presences = the number of cells in original data
```{r}
length(pres.fnetid) == nrow(global.presDF)
```
### create species dataframe with FNETIDs
 (so that FNETIDs are linked to species presences)

```{r}
global.presFNET <- cbind(pres.fnetid, global.presDF) # add fishnet ID to your original dataframe
names(global.presFNET)[1] <- "FNETID" # name change 
head(global.presFNET, 5) # examine
nrow(global.presFNET)
```


```{r}
global.presFNET <- global.presFNET %>% dplyr::select("FNETID",  "decimalLongitude", "decimalLatitude", "scientificName")


df3$scientificName <- NA
global.possabsFNET <- df3

```
```{r}
both <- rbind(global.presFNET, global.possabsFNET)
```
```{r}
global.indexFNET <- both %>% dplyr::distinct(FNETID, .keep_all = TRUE)
```

```{r}
global.indexFNET$in.modFR <- 1
global.indexFNET
```
check: is TRUE?
```{r}
(nrow(both) - nrow(global.indexFNET)) == nrow(global.presFNET)
```

### EXTRACT PSEUDO-ABSENCES [X,Y]’s
### create conditional vectors: FNETIDs by spp locations & in modelling frame
```{r}
p1 <- global.indexFNET
p2.spp <- subset(p1$FNETID, p1$scientificName == 1) # FNETIDs of spp locations
p2.modFR <- subset(p1$FNETID, p1$in.modFR == 1) # FNETIDs in modelling frame
length(p2.spp) # should equal N of spp locations
```

```{r}
length(p2.modFR)
```

#### dropping presence cells

(leaving possible pseudo-absence cell FNETIDs)

```{r}
p3 <- p1[!p1$FNETID %in% p2.spp, ] # background from fishnet
p4 <- p1[!p1$FNETID %in% p2.spp & p1$FNETID %in% p2.modFR, ] # background from modelling frame
pseu.bufpt <- p4 # new name to dataframe: this dataframe used from now on
```

#### Checking...

```{r}
length(p1$FNETID) # N of FISHNET
```
```{r}
dim(p3)[1] # N of FISHNET minus N spp locations
```
```{r}
table(p1$scientificName)[[1]] # N spp locations
```
```{r}
dim(p3)[1] + table(p1$scientificName)[[1]] # should equal N of FISHNET
```
```{r}
length(p2.modFR) # N of modelling frame
```
```{r}
dim(p4)[1] # N modelling frame - N spp locations
```
```{r}
dim(p4)[1] + table(p1$scientificName)[[1]] # should equal N modelling frame
```
```{r}
# recall ...
table(p1$scientificName)[[1]] # N of spp locations
```
```{r}
head(pseu.bufpt, 2) # dataframe from which samples drawn
```
```{r}
nrow(pseu.bufpt)
```

#### Drawing Pseudo-Absences

```{r}
#   N=2*No. pres
set.seed(1234) # set seed to ensure repeatability
pseu.srs2 <- pseu.bufpt[sample(1:nrow(pseu.bufpt), 3 * table(p1$scientificName)[[1]], replace = F), ]
pseu.srs2$scientificName <- 0  # assign 0 to pseu.abs  
pseu.srs2$in.modFR <- 1  # assign 1 to in.modFR
dim(pseu.srs2) # dim[1] should equal N spp locations, dim[2] the No. variables
```
```{r}
head(pseu.srs2, 2) # examine
```

### MERGing PSEUDO-ABSENCES WITH TRUE PRESENCE DATAFRAME

```{r}
head(global.presFNET, 2)
```


#### merge with true presences

```{r}
global.PPsA <- merge(global.presFNET, pseu.srs2, by = c("FNETID", "scientificName", "decimalLongitude", "decimalLatitude"), all = T) # merge
global.PPsA$in.modFR <- NULL # drop in.modFR index no longer needed
dim(global.PPsA) # examine
```
```{r}
head(global.PPsA, 2) 
```

### create common x,y from tru pres and pseudo-abs x,y’s
```{r}
# create new vars wgs_x & wgs_y; used later in raster stack extraction
global.PPsA$tr.Lon <- ifelse(global.PPsA$scientificName == 0, global.PPsA$decimalLongitude, global.PPsA$decimalLongitude)
global.PPsA$tr.Lat <- ifelse(global.PPsA$scientificName == 0, global.PPsA$decimalLatitude, global.PPsA$decimalLatitude) 
global.PPsA[352:355, ] # examine a subset
```

### Getting rid of Pseudoabs that are very close to Pres

<!-- ```{r} -->
<!-- global.PPsA <- global.PPsA[order(-global.PPsA$scientificName),] -->

<!-- global.PPsA$temp.lon <- trunc(global.PPsA$tr.Lon*10^1, digits = 4)/ 10^1 -->
<!-- global.PPsA$temp.lat <- trunc(global.PPsA$tr.Lat*10^1, digits = 4)/ 10^1 -->

<!-- global.PPsA <- distinct(global.PPsA, temp.lon, temp.lat, .keep_all= TRUE) %>% dplyr::select(!c(temp.lon, temp.lat)) -->
<!-- global.PPsA -->
<!-- ``` -->

## Getting rid of Pseudoabs that are very close to Pres

```{r}
global.PPsASF <- st_as_sf(global.PPsA, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = FALSE)
class(global.PPsASF)
```
```{r}
pres <- subset(global.PPsASF, global.PPsASF$scientificName ==1)
pseuabs <- subset(global.PPsASF, global.PPsASF$scientificName ==0)
```

#### Making buffered points
```{r}
pres.bufptSF <- st_buffer(pres, dist = 30000)
#union-ing the points into a single polygon
pres.bufptSF <- st_union(pres.bufptSF) %>% st_make_valid() %>% st_as_sf 
plot(pres.bufptSF)
```
```{r}
class(pseuabs)

class(pres.bufptSF)
```

```{r}
discards <- st_join(pseuabs, pres.bufptSF, join = st_intersects, left = FALSE )

#%>% dplyr::select(FNETID, scientificName, decimalLongitude, decimalLatitude,	geometry)

discards
```

```{r}
discards <- as.data.frame(discards) # build dataframe -  redundant, but whatever
unique(discards$scientificName)
```

```{r}
global.PPsA_temp <- merge(global.PPsA, discards, by = c("FNETID","scientificName", "decimalLongitude", "decimalLatitude"), all.x = TRUE)
global.PPsA_temp <- subset(global.PPsA_temp, is.na(global.PPsA_temp$tr.Lon.y)) %>% dplyr::select(FNETID, scientificName, decimalLongitude, decimalLatitude, tr.Lon.x, tr.Lat.x)
global.PPsA_temp
```
```{r}
global.PPsA_temp <- global.PPsA_temp %>% dplyr::distinct(FNETID, .keep_all = TRUE)
global.PPsA_temp
```

```{r}
table(global.PPsA_temp$scientificName)
```
```{r}
global.PPsADF <- global.PPsA_temp
```

### Saving

```{r}
global.PPsASF <- st_as_sf(global.PPsA, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = FALSE)
class(global.PPsASF)
```
```{r}
global.PPsADF <- st_drop_geometry(global.PPsASF) # build dataframe
setwd(path.in.specific)
save("global.PPsADF", file = paste0(spname, "_global.PPsADF.RData"))
head(global.PPsADF, 2) # examine
```

## Point shapefile with geometry in R

```{r}
setwd(path.in.specific)
save("global.PPsASF", file = paste0(spname, "_global.PPsASF.RData"))
head(global.PPsASF, 2) # examine
```

Export as a point shapefile in ESRI format

<!-- ```{r} -->
<!-- setwd(path.in.specific) # output path -->
<!-- st_write(global.PPsASF, dsn = ".", layer = paste0(spname, "_global_PPsASF"), driver = "ESRI Shapefile", delete_layer = T, delete_dsn = T) # output shapefile -->
<!-- ``` -->



## Get Global Environmental Data



```{r}
# get WorldClim bioclimatic variable rasters
#envs <- raster::getData(name = "worldclim", var = "bio", res = 0.5, lat =(60), lon = (180))

# plot(envs)
```
```{r}
# get WorldClim bioclimatic variable rasters
#elev <- raster::getData(name = "worldclim", var = "alt", res = 0.5, lat =180, lon = 90 )
#elev
```
```{r}
#combined <- raster::stack(envs, elev)
#names(combined)
```

For 30s resolution
Just getting all
```{r}
setwd(path.in.general)
baseline <- list.files(pattern = "wc2.1_30s") # list of .img files; $ strips extra
baseline
```

```{r}
setwd(path.in.general)
combined <- terra::rast(baseline)# examine
combined
```

```{r}
names(combined) <- c("bio1", "bio12", "bio15" )
names(combined)

combined 
```

```{r}
combined <- terra::crop(combined, global.bufptSF)
combined
#raster::crop(raster::rasterize(global.bufbboxSP, template1), global.bufbboxSP)
```

```{r}
setwd(path.in.specific)
#save(combined, file = paste0(spname, "bioclimstack.RData") # save .RData
terra::writeRaster(combined, filename = paste0(spname, "_bioclimstack.tif"),  overwrite = T) # save as .tif file
```

```{r}
setwd(path.in.specific)
#bioclim <- get(load("bioclimstack.RData"))
bioclim <- terra::rast(paste0(spname, "_bioclimstack.tif"))
bioclim
```


### Extract predictor variables for a bioclim vars files using the presence:absence [X,Y]’s

##### First, get the presence-absence data

```{r}
pres.abs <- global.PPsADF
head(pres.abs, 2)
```
```{r}
table(pres.abs$scientificName) # examine frequencies
```

```{r}
sdf <- st_as_sf(pres.abs, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = F) # remove=F retains input x,y)
class(sdf)
head(sdf, 2) # examine
```

```{r}
t1 <- terra::extract(bioclim, pres.abs[c("tr.Lon", "tr.Lat")])
t1[t1 == "NaN"] <- NA
head(t1, 30) # examine extracted matrix
```

There might be lots of NAs here if you buffered by a large distance so that the pseudo abs fall in the ocean.


### Create a new dataframe by binding the extracted predictor variable values to the pres abs dataframe

```{r}
global.trTOPO <- cbind(pres.abs, t1) # bind to train dataframe
  head(global.trTOPO, 5) # examine training data frame
```
```{r}
nrow(pres.abs)
```
```{r}
dim(t1)
```

```{r}
# examine extractions
nrow(subset(global.trTOPO, is.na(as.character(global.trTOPO$bio1))))
```
How many NA's exist? preferably very few


```{r}
global.trTOPOSF <- st_as_sf(global.trTOPO, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = FALSE)
class(global.trTOPOSF)
```

```{r}
zeros <- subset(global.trTOPOSF, scientificName == 0)
ones <- subset(global.trTOPOSF, scientificName == 1)


plot(st_geometry(zeros), axes = T,col = "blue")
plot(st_geometry(ones), add = T,  col = "red")
```
HUMAN DECISION MAKING NEEDED HERE:
if the number of zeros (absences) is not around 2-3 X the number of ones (presences), adjust the value 
under the header #### Drawing Pseudo-Absences where it's multiplying by table()...

```{r}
nrow(zeros)
```
```{r}
nrow(ones)
```


##### Saving
```{r}
setwd(path.in.specific)
write.csv(global.trTOPO, file = paste0(spname, "_global_trTOPO.csv"), row.names = F) # save .csv
save(global.trTOPO, file = "_global.trTOPO.RData") # save .RData
#st_write(global.trTOPOSF, dsn = ".", layer = paste0(spname, "_global.trTOPOSF"), driver = "ESRI Shapefile", delete_layer = T, delete_dsn = T) # output shapefile
```

## EXAMINE ENVIRONMENTAL RELATIONSHIPS


```{r}
setwd(path.in.specific)
tr.data <- read.csv( file = paste0(spname, "_global_trTOPO.csv"))
tr.data <- subset(tr.data, !is.na(tr.data$bio1))
dim(tr.data)
```
```{r}
table(tr.data$scientificName)
```
#### Description of World BIOCLIM environmental variables
    BIO1 = Annual Mean Temperature
    BIO2 = Mean Diurnal Range (Mean of monthly (max temp - min temp))
    BIO3 = Isothermality (BIO2/BIO7) (×100)
    BIO4 = Temperature Seasonality (standard deviation ×100)
    BIO5 = Max Temperature of Warmest Month
    BIO6 = Min Temperature of Coldest Month
    BIO7 = Temperature Annual Range (BIO5-BIO6)
    BIO8 = Mean Temperature of Wettest Quarter
    BIO9 = Mean Temperature of Driest Quarter
    BIO10 = Mean Temperature of Warmest Quarter
    BIO11 = Mean Temperature of Coldest Quarter
    BIO12 = Annual Precipitation
    BIO13 = Precipitation of Wettest Month
    BIO14 = Precipitation of Driest Month
    BIO15 = Precipitation Seasonality (Coefficient of Variation)
    BIO16 = Precipitation of Wettest Quarter
    BIO17 = Precipitation of Driest Quarter
    BIO18 = Precipitation of Warmest Quarter
    BIO19 = Precipitation of Coldest Quarter

```{r}
tr.data
```

```{r}
occurrences <- c("FNETID", "scientificName", "tr.Lon", "tr.Lat")

allpreds <- c('bio1', 'bio12', 'bio15')
```


```{r}
tr.data <- cbind(tr.data %>% dplyr::select(all_of(occurrences)), tr.data %>% dplyr::select(all_of(allpreds)))
tr.data$pred_type <- "allpreds"
```

### CORRELATIONS AMONG ALL PREDICTORS
```{r}
tr.data
```

```{r}
# numeric correlations
#Using spearman because it has no assumption of normality
  cut.point <- 0.7 # set cutpoint for correlation
  c1 <- cor(tr.data[, c(5:7)], use = "pairwise.complete.obs", method = "spearman") # est. correlation
```
```{r}
c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
c2 # examine; FALSE indicates cor<cutpoint 
```

START MODIFIED panel.cor CORRELATION FUNCTION
```{r}
#   determine correlations among predictor variables: modified from 
#   http://addictedtor.free.fr/graphiques/graphcode.php?graph=137
panel.cor <- function(x, y, digits=2, prefix="", cex.cor) 
  { usr <- par("usr"); on.exit(par(usr)) 
    par(usr = c(0, 1, 0, 1)) 
    r <- abs(cor(x, y, use = "pairwise.complete.obs")) 
    txt <- format(c(r, 0.123456789), digits=digits)[1] 
    txt <- paste(prefix, txt, sep="") 
    if(missing(cex.cor)) cex <- 0.8/strwidth(txt) 

    test <- cor.test(x,y) 
    # borrowed from printCoefmat
    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, 
                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                  symbols = c("***", "**", "*", ".", " ")) 

    text(0.5, 0.5, txt, cex = cex * r)
    text(.8, .8, Signif, cex=cex, col=2) 
}
# END MODIFIED panel.cor CORRELATION FUNCTION
```

### CORRELATIONS BETWEEN TEMPERATURE PREDICTORS
```{r}
# numeric correlations
#Using spearman because it has no assumption of normality
cut.point <- 0.7 # set cutpoint for correlation
c1 <- cor(tr.data[, c(5:(ncol(tr.data)-1))], use = "pairwise.complete.obs",method = "spearman") # est. correlation
c2 <- subset(c1 > cut.point | c1 < -cut.point) # matrix of cor>cutpoint
```
```{r}
# plot correlations using modified panel.cor function
  pairs(tr.data[, c(5:(ncol(tr.data)-1))], lower.panel = panel.smooth, 
    upper.panel = panel.cor, main = "All Variables")
```
START VARIABLE IMPORTANCE AMONG TEMPERATURE PREDICTORS
Modified from: Niklaus E. Zimmermann, WSL / ETH Zurich
```{r}
#### START function variable importance
varimp.glm <- function(tr.spp, tr.var, pres, pf, pl) {
  tmp.mat <- matrix(ncol = 2, nrow = (pl - pf + 1))
  for (i in pf:pl) {
    # option: linear+quadratic; linear only
    tmp <- glm(tr.spp[, pres] ~ tr.var[, i] + I((tr.var[, i])^2), na.action = na.omit, 
      family = binomial)
    # linear only glm
    #tmp <- glm(tr.spp[, pres] ~ tr.var[, i], na.action = na.omit, family = binomial)
    tmp.mat[(i - pf + 1), 1] <- tmp$aic
    tmp.mat[(i - pf + 1), 2] <- (1 - (tmp$deviance/tmp$null.deviance))
    }
  return(tmp.mat)
  } 
#### END function variable importance
```

```{r}
# estimate VIP values => AIC & Adj deviance
  tr.vip <- tr.data[, c(2, 5:(ncol(tr.data)-1))] # keep only P/A & predictors
  pres <- 1 # column for presence:absence
  v.start <- 2 # column start predictor variables
  v.stop <- ncol(tr.vip) # last column predictor variables
  v.num <- v.stop - 1 # number predictor variables
  dev.fit <- varimp.glm(tr.vip, tr.vip, pres, v.start, v.stop) # call VIP function
  dev.fit # output matrix; col=1 AIC, col=2 Adj deviance
```
```{r}
# built basic barplot if desired
  d.max <- ceiling(signif(max(dev.fit[, 2]), 2) * 10)/10 # max of y-axis
  ylim.r <- range(0, d.max) # range y-axis
  x.labs <- names(tr.vip[2:v.stop]) # x-axis labels
  barplot(dev.fit[, 2], col = "darkgreen", ylim = ylim.r, main = "tr.data VIPs", 
    ylab = "adj.D2", names = x.labs) # barplot
  abline(h = 0) # add horizontal line
  abline(mean(dev.fit[, 2]), 0, lt = 3) # ref lines; dash=mean adj.dev 
```

```{r}
keep <- c('bio1', 'bio12', 'bio15')
tr.picked <- cbind(tr.data %>% dplyr::select(all_of(occurrences)), tr.data %>% dplyr::select(all_of(keep)))
head(tr.picked)
```
```{r}
par(mfrow = c(1, 3))
boxplot(tr.picked[,length(tr.picked) - length(keep) ]~ tr.picked$scientificName, xlab = "Presence:Absence", 
    ylab = keep[1])

boxplot(tr.picked[,length(tr.picked) - length(keep) + 1 ] ~ tr.picked$scientificName, xlab = "Presence:Absence",
    ylab = keep[2])

boxplot(tr.picked[,length(tr.picked) - length(keep) + 2 ] ~ tr.picked$scientificName, xlab = "Presence:Absence",
    ylab = keep[3])



```

```{r}
tr.picked %>% 
  pivot_longer(names_to = "covariate", values_to = "value", - (FNETID:tr.Lat)) %>% 
  ggplot() +
  geom_density(aes(x = value, y = ..density.., color = factor(scientificName))) +

  facet_wrap(~covariate, scales = "free") +
  theme_minimal()
```

### Saving

```{r}
setwd(path.in.specific)
save(keep, file = paste0( spname, "_list_picked_vars_global.RData")) # save .RData
```

```{r}
setwd(path.in.specific)
write.csv(tr.picked, file = paste0( spname, "_tr_global_pickedvars.csv"), row.names = F) # save .csv
save(tr.picked, file = paste0( spname, "_tr_global_pickedvars.RData")) # save .RData

tr_globalSF <- st_as_sf(tr.picked, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = FALSE)
save(tr_globalSF, file = paste0( spname, "_tr_globalSF_pickedvars.RData")) # save .RData
st_write(tr_globalSF, dsn = ".", layer = paste0( spname, "_tr_globalSF_pickedvars"), driver = "ESRI Shapefile", delete_layer = T, delete_dsn = T) #
```

```{r}
setwd(path.in.specific)
write.csv(tr.data, file = paste0( spname, "_tr_global_allvars.csv"), row.names = F) # save .csv
save(tr.data, file = paste0( spname, "_tr_global_allvars.RData")) # save .RData

tr_globalSF <- st_as_sf(tr.data, coords = c("tr.Lon", "tr.Lat"), crs = prj.wgs84, remove = FALSE)
save(tr_globalSF, file = paste0( spname, "_tr_globalSF_allvars.RData")) # save .RData
st_write(tr_globalSF, dsn = ".", layer = paste0( spname, "_tr_globalSF_allvars"), driver = "ESRI Shapefile", delete_layer = T, delete_dsn = T) # 
```

```{r}
nowtime <- Sys.time()
elapsed = nowtime - starttime
print(elapsed)
```

